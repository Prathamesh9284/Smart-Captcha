{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse the dataset\n",
    "def parse_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    # Convert timestamp to datetime\n",
    "    data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "data_human = parse_data(\"human.csv\")\n",
    "data_bot = parse_data(\"bot.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract features\n",
    "def extract_features(data):\n",
    "    # Calculate the time difference between consecutive movements in milliseconds\n",
    "    data['time_diff'] = data['timestamp'].diff().dt.total_seconds().fillna(0) * 1000\n",
    "    \n",
    "    # Calculate the Euclidean distance between consecutive points\n",
    "    data['distance'] = np.sqrt((data['x'].diff()**2) + (data['y'].diff()**2)).fillna(0)\n",
    "    \n",
    "    # Calculate the speed (distance/time)\n",
    "    data['speed'] = data['distance'] / data['time_diff'].replace(0, np.nan).fillna(0)\n",
    "    \n",
    "    # Calculate the direction of movement\n",
    "    data['direction'] = np.arctan2(data['y'].diff(), data['x'].diff()).fillna(0)\n",
    "    \n",
    "    # Optional: Calculate curvature between three consecutive points\n",
    "    data['curvature'] = data['direction'].diff().fillna(0)\n",
    "    \n",
    "    return data[['time_diff', 'distance', 'speed', 'direction', 'curvature']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and labels\n",
    "features_human = extract_features(data_human)\n",
    "features_bot = extract_features(data_bot)\n",
    "\n",
    "features_human['label'] = 0  # Human label\n",
    "features_bot['label'] = 1    # Bot label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the datasets\n",
    "dataset = pd.concat([features_human, features_bot]).reset_index(drop=True)\n",
    "\n",
    "X = dataset.drop('label', axis=1).dropna()\n",
    "y = dataset['label'][X.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define multiple classifiers\n",
    "classifiers = {\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Support Vector Machine\": make_pipeline(StandardScaler(), SVC()),\n",
    "    \"Logistic Regression\": make_pipeline(StandardScaler(), LogisticRegression()),\n",
    "    \"K-Nearest Neighbors\": make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=1)) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest has been trained successfully.\n",
      "Support Vector Machine has been trained successfully.\n",
      "Logistic Regression has been trained successfully.\n",
      "K-Nearest Neighbors has been trained successfully.\n"
     ]
    }
   ],
   "source": [
    "# Train all classifiers\n",
    "trained_models = {}\n",
    "for name, model in classifiers.items():\n",
    "    model.fit(X, y)\n",
    "    trained_models[name] = model\n",
    "    print(f\"{name} has been trained successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict new data using all models\n",
    "def predict_new_data(file_path, trained_models):\n",
    "    # Parse the new data file\n",
    "    new_data = parse_data(file_path)\n",
    "    \n",
    "    # Extract features from the new data\n",
    "    features_new_data = extract_features(new_data).dropna()\n",
    "    \n",
    "    predictions = {}\n",
    "    for name, model in trained_models.items():\n",
    "        # Predict using the trained model\n",
    "        preds = model.predict(features_new_data)\n",
    "        \n",
    "        # Count the predictions\n",
    "        human_count = (preds == 0).sum()\n",
    "        bot_count = (preds == 1).sum()\n",
    "        \n",
    "        # Majority voting to determine overall classification\n",
    "        overall_prediction = \"Human\" if human_count > bot_count else \"Bot\"\n",
    "        predictions[name] = overall_prediction\n",
    "        print(f\"The overall prediction for '{file_path}' using {name} is: {overall_prediction}\")\n",
    "    \n",
    "    # return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall prediction for 'human_test.csv' using Random Forest is: Human\n",
      "The overall prediction for 'human_test.csv' using Support Vector Machine is: Human\n",
      "The overall prediction for 'human_test.csv' using Logistic Regression is: Human\n",
      "The overall prediction for 'human_test.csv' using K-Nearest Neighbors is: Human\n"
     ]
    }
   ],
   "source": [
    "file_path = \"human_test.csv\"  # Replace with your actual file path\n",
    "prediction = predict_new_data(file_path, trained_models)\n",
    "# print(f\"The overall prediction for the file '{file_path}' is: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall prediction for 'bot_test.csv' using Random Forest is: Bot\n",
      "The overall prediction for 'bot_test.csv' using Support Vector Machine is: Human\n",
      "The overall prediction for 'bot_test.csv' using Logistic Regression is: Bot\n",
      "The overall prediction for 'bot_test.csv' using K-Nearest Neighbors is: Bot\n"
     ]
    }
   ],
   "source": [
    "file_path = \"bot_test.csv\"  # Replace with your actual file path\n",
    "prediction = predict_new_data(file_path, trained_models)\n",
    "# print(f\"The overall prediction for the file '{file_path}' is: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
